#Random Forest and AdaBoost

This project demonstrates the use of ensemble learning methods, specifically **Random Forest** and **AdaBoost**, for classification tasks. It includes hyperparameter tuning, model evaluation, and visualizations to showcase the impact of various parameters on model performance.
## Project Overview
This project explores tree-based ensemble learning techniques:
1. **Bagging (Random Forest):**
   - Evaluates the effect of the number of trees (`n_estimators`) and feature sampling (`max_features`) on model performance.
2. **Boosting (AdaBoost):**
   - Analyzes the impact of hyperparameters like `learning_rate` and `n_estimators` on model accuracy.
3. Models are trained, validated, and tested on a custom dataset.
